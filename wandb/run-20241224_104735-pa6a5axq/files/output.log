<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="MNIST_model" type="MLP" qualifier="__main__" value="MLP%28%0A  %28fc1%29%3A Linear%28in_features=784%2C out_features=128%2C bias=True%29%0A  %28relu1%29%3A ReLU%28%29%0A  %28fc2%29%3A Linear%28in_features=128%2C out_features=128%2C bias=True%29%0A  %28relu2%29%3A ReLU%28%29%0A  %28fc3%29%3A Linear%28in_features=128%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" />
<var name="batch_size" type="int" qualifier="builtins" value="64" />
<var name="criterion" type="CrossEntropyLoss" qualifier="torch.nn.modules.loss" value="CrossEntropyLoss%28%29" isContainer="True" />
<var name="epoch" type="int" qualifier="builtins" value="299" />
<var name="epochs" type="int" qualifier="builtins" value="300" />
<var name="example_data" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B%5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ......%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%5D%5D%5D%29" isContainer="True" shape="(64, 1, 28, 28)" />
<var name="example_labels" type="Tensor" qualifier="torch" value="tensor%28%5B7%2C 2%2C 1%2C 0%2C 4%2C 1%2C 4%2C 9%2C 5%2C 9%2C 0%2C 6%2C 9%2C 0%2C 1%2C 5%2C 9%2C 7%2C 3%2C 4%2C 9%2C 6%2C 6%2C 5%2C%0A        4%2C 0%2C 7%2C 4%2C 0%2C 1%2C 3%2C 1%2C 3%2C 4%2C 7%2C 2%2C 7%2C 1%2C 2%2C 1%2C 1%2C 7%2C 4%2C 2%2C 3%2C 5%2C 1%2C 2%2C%0A        4%2C 4%2C 6%2C 3%2C 5%2C 5%2C 6%2C 0%2C 4%2C 1%2C 9%2C 5%2C 7%2C 8%2C 9%2C 3%5D%29" isContainer="True" shape="(64,)" />
<var name="examples" type="_SingleProcessDataLoaderIter" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x1518d98b0&gt;" isContainer="True" shape="157" />
<var name="fig" type="Figure" qualifier="matplotlib.figure" value="%3CFigure size 640x480 with 6 Axes&gt;" isContainer="True" />
<var name="hidden_size" type="int" qualifier="builtins" value="128" />
<var name="i" type="int" qualifier="builtins" value="5" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="model" type="MLP" qualifier="__main__" value="MLP%28%0A  %28fc1%29%3A Linear%28in_features=784%2C out_features=128%2C bias=True%29%0A  %28relu1%29%3A ReLU%28%29%0A  %28fc2%29%3A Linear%28in_features=128%2C out_features=128%2C bias=True%29%0A  %28relu2%29%3A ReLU%28%29%0A  %28fc3%29%3A Linear%28in_features=128%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" />
<var name="optimizer" type="Adam" qualifier="torch.optim.adam" value="Adam %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    initial_lr%3A 0.001%0A    lr%3A 3.0517578125e-08%0A    maximize%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="outputs" type="Tensor" qualifier="torch" value="tensor%28%5B%5B-4.4979e%2B01%2C -3.6314e%2B01%2C -2.4818e%2B01%2C -1.2241e-01%2C -5.0165e%2B01%2C%0A         -3.6805e%2B01%2C -8.5459e%2B01%2C  4.2051e%2B01%2C -4.1...-4.7492e%2B01%2C -1.0279e%2B01%2C  3.9232e%2B01%2C -9.2660e%2B01%2C%0A         -4.2278e%2B01%2C -1.0490e%2B02%2C -3.3722e%2B01%2C -2.4868e%2B01%2C -2.3130e%2B01%5D%5D%29" isContainer="True" shape="(64, 10)" />
<var name="pred" type="Tensor" qualifier="torch" value="tensor%28%5B7%2C 2%2C 1%2C 0%2C 4%2C 1%2C 4%2C 9%2C 5%2C 9%2C 0%2C 6%2C 9%2C 0%2C 1%2C 5%2C 9%2C 7%2C 3%2C 4%2C 9%2C 6%2C 6%2C 5%2C%0A        4%2C 0%2C 7%2C 4%2C 0%2C 1%2C 3%2C 1%2C 3%2C 4%2C 7%2C 2%2C 7%2C 1%2C 2%2C 1%2C 1%2C 7%2C 4%2C 2%2C 3%2C 5%2C 1%2C 2%2C%0A        4%2C 4%2C 6%2C 3%2C 5%2C 5%2C 6%2C 0%2C 4%2C 1%2C 9%2C 5%2C 7%2C 8%2C 9%2C 3%5D%29" isContainer="True" shape="(64,)" />
<var name="scheduler" type="StepLR" qualifier="torch.optim.lr_scheduler" value="%3Ctorch.optim.lr_scheduler.StepLR object at 0x151a8d280&gt;" isContainer="True" />
<var name="test_acc" type="float" qualifier="builtins" value="0.9837" />
<var name="test_dataset" type="MNIST" qualifier="torchvision.datasets.mnist" value="Dataset MNIST%0A    Number of datapoints%3A 10000%0A    Root location%3A ./data%0A    Split%3A Test%0A    StandardTransform%0ATransform%3A Compose%28%0A               ToTensor%28%29%0A               Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A           %29" isContainer="True" shape="10000" />
<var name="test_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x151a8ddc0&gt;" isContainer="True" shape="157" />
<var name="test_loss" type="float" qualifier="builtins" value="0.17489853962994478" />
<var name="train_dataset" type="MNIST" qualifier="torchvision.datasets.mnist" value="Dataset MNIST%0A    Number of datapoints%3A 60000%0A    Root location%3A ./data%0A    Split%3A Train%0A    StandardTransform%0ATransform%3A Compose%28%0A               ToTensor%28%29%0A               Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A           %29" isContainer="True" shape="60000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x1518e4160&gt;" isContainer="True" shape="938" />
<var name="training_acc" type="float" qualifier="builtins" value="1.0" />
<var name="training_loss" type="float" qualifier="builtins" value="2.1618982535816112e-08" />
<var name="transform" type="Compose" qualifier="torchvision.transforms.transforms" value="Compose%28%0A    ToTensor%28%29%0A    Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A%29" isContainer="True" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="MNIST_model" type="MLP" qualifier="__main__" value="MLP%28%0A  %28fc1%29%3A Linear%28in_features=784%2C out_features=128%2C bias=True%29%0A  %28relu1%29%3A ReLU%28%29%0A  %28fc2%29%3A Linear%28in_features=128%2C out_features=128%2C bias=True%29%0A  %28relu2%29%3A ReLU%28%29%0A  %28fc3%29%3A Linear%28in_features=128%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" />
<var name="batch_size" type="int" qualifier="builtins" value="64" />
<var name="criterion" type="CrossEntropyLoss" qualifier="torch.nn.modules.loss" value="CrossEntropyLoss%28%29" isContainer="True" />
<var name="epoch" type="int" qualifier="builtins" value="299" />
<var name="epochs" type="int" qualifier="builtins" value="300" />
<var name="example_data" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B%5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ......%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%5D%5D%5D%29" isContainer="True" shape="(64, 1, 28, 28)" />
<var name="example_labels" type="Tensor" qualifier="torch" value="tensor%28%5B7%2C 2%2C 1%2C 0%2C 4%2C 1%2C 4%2C 9%2C 5%2C 9%2C 0%2C 6%2C 9%2C 0%2C 1%2C 5%2C 9%2C 7%2C 3%2C 4%2C 9%2C 6%2C 6%2C 5%2C%0A        4%2C 0%2C 7%2C 4%2C 0%2C 1%2C 3%2C 1%2C 3%2C 4%2C 7%2C 2%2C 7%2C 1%2C 2%2C 1%2C 1%2C 7%2C 4%2C 2%2C 3%2C 5%2C 1%2C 2%2C%0A        4%2C 4%2C 6%2C 3%2C 5%2C 5%2C 6%2C 0%2C 4%2C 1%2C 9%2C 5%2C 7%2C 8%2C 9%2C 3%5D%29" isContainer="True" shape="(64,)" />
<var name="examples" type="_SingleProcessDataLoaderIter" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x1518d98b0&gt;" isContainer="True" shape="157" />
<var name="fig" type="Figure" qualifier="matplotlib.figure" value="%3CFigure size 640x480 with 6 Axes&gt;" isContainer="True" />
<var name="hidden_size" type="int" qualifier="builtins" value="128" />
<var name="i" type="int" qualifier="builtins" value="5" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="model" type="MLP" qualifier="__main__" value="MLP%28%0A  %28fc1%29%3A Linear%28in_features=784%2C out_features=128%2C bias=True%29%0A  %28relu1%29%3A ReLU%28%29%0A  %28fc2%29%3A Linear%28in_features=128%2C out_features=128%2C bias=True%29%0A  %28relu2%29%3A ReLU%28%29%0A  %28fc3%29%3A Linear%28in_features=128%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" />
<var name="optimizer" type="Adam" qualifier="torch.optim.adam" value="Adam %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    initial_lr%3A 0.001%0A    lr%3A 3.0517578125e-08%0A    maximize%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="outputs" type="Tensor" qualifier="torch" value="tensor%28%5B%5B-4.4979e%2B01%2C -3.6314e%2B01%2C -2.4818e%2B01%2C -1.2241e-01%2C -5.0165e%2B01%2C%0A         -3.6805e%2B01%2C -8.5459e%2B01%2C  4.2051e%2B01%2C -4.1...-4.7492e%2B01%2C -1.0279e%2B01%2C  3.9232e%2B01%2C -9.2660e%2B01%2C%0A         -4.2278e%2B01%2C -1.0490e%2B02%2C -3.3722e%2B01%2C -2.4868e%2B01%2C -2.3130e%2B01%5D%5D%29" isContainer="True" shape="(64, 10)" />
<var name="pred" type="Tensor" qualifier="torch" value="tensor%28%5B7%2C 2%2C 1%2C 0%2C 4%2C 1%2C 4%2C 9%2C 5%2C 9%2C 0%2C 6%2C 9%2C 0%2C 1%2C 5%2C 9%2C 7%2C 3%2C 4%2C 9%2C 6%2C 6%2C 5%2C%0A        4%2C 0%2C 7%2C 4%2C 0%2C 1%2C 3%2C 1%2C 3%2C 4%2C 7%2C 2%2C 7%2C 1%2C 2%2C 1%2C 1%2C 7%2C 4%2C 2%2C 3%2C 5%2C 1%2C 2%2C%0A        4%2C 4%2C 6%2C 3%2C 5%2C 5%2C 6%2C 0%2C 4%2C 1%2C 9%2C 5%2C 7%2C 8%2C 9%2C 3%5D%29" isContainer="True" shape="(64,)" />
<var name="scheduler" type="StepLR" qualifier="torch.optim.lr_scheduler" value="%3Ctorch.optim.lr_scheduler.StepLR object at 0x151a8d280&gt;" isContainer="True" />
<var name="test_acc" type="float" qualifier="builtins" value="0.9837" />
<var name="test_dataset" type="MNIST" qualifier="torchvision.datasets.mnist" value="Dataset MNIST%0A    Number of datapoints%3A 10000%0A    Root location%3A ./data%0A    Split%3A Test%0A    StandardTransform%0ATransform%3A Compose%28%0A               ToTensor%28%29%0A               Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A           %29" isContainer="True" shape="10000" />
<var name="test_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x151a8ddc0&gt;" isContainer="True" shape="157" />
<var name="test_loss" type="float" qualifier="builtins" value="0.17489853962994478" />
<var name="train_dataset" type="MNIST" qualifier="torchvision.datasets.mnist" value="Dataset MNIST%0A    Number of datapoints%3A 60000%0A    Root location%3A ./data%0A    Split%3A Train%0A    StandardTransform%0ATransform%3A Compose%28%0A               ToTensor%28%29%0A               Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A           %29" isContainer="True" shape="60000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x1518e4160&gt;" isContainer="True" shape="938" />
<var name="training_acc" type="float" qualifier="builtins" value="1.0" />
<var name="training_loss" type="float" qualifier="builtins" value="2.1618982535816112e-08" />
<var name="transform" type="Compose" qualifier="torchvision.transforms.transforms" value="Compose%28%0A    ToTensor%28%29%0A    Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A%29" isContainer="True" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="MNIST_model" type="MLP" qualifier="__main__" value="MLP%28%0A  %28fc1%29%3A Linear%28in_features=784%2C out_features=128%2C bias=True%29%0A  %28relu1%29%3A ReLU%28%29%0A  %28fc2%29%3A Linear%28in_features=128%2C out_features=128%2C bias=True%29%0A  %28relu2%29%3A ReLU%28%29%0A  %28fc3%29%3A Linear%28in_features=128%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" />
<var name="batch_size" type="int" qualifier="builtins" value="64" />
<var name="criterion" type="CrossEntropyLoss" qualifier="torch.nn.modules.loss" value="CrossEntropyLoss%28%29" isContainer="True" />
<var name="epoch" type="int" qualifier="builtins" value="299" />
<var name="epochs" type="int" qualifier="builtins" value="300" />
<var name="example_data" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B%5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ......%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%5D%5D%5D%29" isContainer="True" shape="(64, 1, 28, 28)" />
<var name="example_labels" type="Tensor" qualifier="torch" value="tensor%28%5B7%2C 2%2C 1%2C 0%2C 4%2C 1%2C 4%2C 9%2C 5%2C 9%2C 0%2C 6%2C 9%2C 0%2C 1%2C 5%2C 9%2C 7%2C 3%2C 4%2C 9%2C 6%2C 6%2C 5%2C%0A        4%2C 0%2C 7%2C 4%2C 0%2C 1%2C 3%2C 1%2C 3%2C 4%2C 7%2C 2%2C 7%2C 1%2C 2%2C 1%2C 1%2C 7%2C 4%2C 2%2C 3%2C 5%2C 1%2C 2%2C%0A        4%2C 4%2C 6%2C 3%2C 5%2C 5%2C 6%2C 0%2C 4%2C 1%2C 9%2C 5%2C 7%2C 8%2C 9%2C 3%5D%29" isContainer="True" shape="(64,)" />
<var name="examples" type="_SingleProcessDataLoaderIter" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x1518d98b0&gt;" isContainer="True" shape="157" />
<var name="fig" type="Figure" qualifier="matplotlib.figure" value="%3CFigure size 640x480 with 6 Axes&gt;" isContainer="True" />
<var name="hidden_size" type="int" qualifier="builtins" value="128" />
<var name="i" type="int" qualifier="builtins" value="5" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="model" type="MLP" qualifier="__main__" value="MLP%28%0A  %28fc1%29%3A Linear%28in_features=784%2C out_features=128%2C bias=True%29%0A  %28relu1%29%3A ReLU%28%29%0A  %28fc2%29%3A Linear%28in_features=128%2C out_features=128%2C bias=True%29%0A  %28relu2%29%3A ReLU%28%29%0A  %28fc3%29%3A Linear%28in_features=128%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" />
<var name="optimizer" type="Adam" qualifier="torch.optim.adam" value="Adam %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    initial_lr%3A 0.001%0A    lr%3A 3.0517578125e-08%0A    maximize%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="outputs" type="Tensor" qualifier="torch" value="tensor%28%5B%5B-4.4979e%2B01%2C -3.6314e%2B01%2C -2.4818e%2B01%2C -1.2241e-01%2C -5.0165e%2B01%2C%0A         -3.6805e%2B01%2C -8.5459e%2B01%2C  4.2051e%2B01%2C -4.1...-4.7492e%2B01%2C -1.0279e%2B01%2C  3.9232e%2B01%2C -9.2660e%2B01%2C%0A         -4.2278e%2B01%2C -1.0490e%2B02%2C -3.3722e%2B01%2C -2.4868e%2B01%2C -2.3130e%2B01%5D%5D%29" isContainer="True" shape="(64, 10)" />
<var name="pred" type="Tensor" qualifier="torch" value="tensor%28%5B7%2C 2%2C 1%2C 0%2C 4%2C 1%2C 4%2C 9%2C 5%2C 9%2C 0%2C 6%2C 9%2C 0%2C 1%2C 5%2C 9%2C 7%2C 3%2C 4%2C 9%2C 6%2C 6%2C 5%2C%0A        4%2C 0%2C 7%2C 4%2C 0%2C 1%2C 3%2C 1%2C 3%2C 4%2C 7%2C 2%2C 7%2C 1%2C 2%2C 1%2C 1%2C 7%2C 4%2C 2%2C 3%2C 5%2C 1%2C 2%2C%0A        4%2C 4%2C 6%2C 3%2C 5%2C 5%2C 6%2C 0%2C 4%2C 1%2C 9%2C 5%2C 7%2C 8%2C 9%2C 3%5D%29" isContainer="True" shape="(64,)" />
<var name="scheduler" type="StepLR" qualifier="torch.optim.lr_scheduler" value="%3Ctorch.optim.lr_scheduler.StepLR object at 0x151a8d280&gt;" isContainer="True" />
<var name="test_acc" type="float" qualifier="builtins" value="0.9837" />
<var name="test_dataset" type="MNIST" qualifier="torchvision.datasets.mnist" value="Dataset MNIST%0A    Number of datapoints%3A 10000%0A    Root location%3A ./data%0A    Split%3A Test%0A    StandardTransform%0ATransform%3A Compose%28%0A               ToTensor%28%29%0A               Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A           %29" isContainer="True" shape="10000" />
<var name="test_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x151a8ddc0&gt;" isContainer="True" shape="157" />
<var name="test_loss" type="float" qualifier="builtins" value="0.17489853962994478" />
<var name="train_dataset" type="MNIST" qualifier="torchvision.datasets.mnist" value="Dataset MNIST%0A    Number of datapoints%3A 60000%0A    Root location%3A ./data%0A    Split%3A Train%0A    StandardTransform%0ATransform%3A Compose%28%0A               ToTensor%28%29%0A               Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A           %29" isContainer="True" shape="60000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x1518e4160&gt;" isContainer="True" shape="938" />
<var name="training_acc" type="float" qualifier="builtins" value="1.0" />
<var name="training_loss" type="float" qualifier="builtins" value="2.1618982535816112e-08" />
<var name="transform" type="Compose" qualifier="torchvision.transforms.transforms" value="Compose%28%0A    ToTensor%28%29%0A    Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A%29" isContainer="True" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="MNIST_model" type="MLP" qualifier="__main__" value="MLP%28%0A  %28fc1%29%3A Linear%28in_features=784%2C out_features=128%2C bias=True%29%0A  %28relu1%29%3A ReLU%28%29%0A  %28fc2%29%3A Linear%28in_features=128%2C out_features=128%2C bias=True%29%0A  %28relu2%29%3A ReLU%28%29%0A  %28fc3%29%3A Linear%28in_features=128%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" />
<var name="batch_size" type="int" qualifier="builtins" value="64" />
<var name="criterion" type="CrossEntropyLoss" qualifier="torch.nn.modules.loss" value="CrossEntropyLoss%28%29" isContainer="True" />
<var name="epoch" type="int" qualifier="builtins" value="299" />
<var name="epochs" type="int" qualifier="builtins" value="300" />
<var name="example_data" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B%5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ......%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%5D%5D%5D%29" isContainer="True" shape="(64, 1, 28, 28)" />
<var name="example_labels" type="Tensor" qualifier="torch" value="tensor%28%5B7%2C 2%2C 1%2C 0%2C 4%2C 1%2C 4%2C 9%2C 5%2C 9%2C 0%2C 6%2C 9%2C 0%2C 1%2C 5%2C 9%2C 7%2C 3%2C 4%2C 9%2C 6%2C 6%2C 5%2C%0A        4%2C 0%2C 7%2C 4%2C 0%2C 1%2C 3%2C 1%2C 3%2C 4%2C 7%2C 2%2C 7%2C 1%2C 2%2C 1%2C 1%2C 7%2C 4%2C 2%2C 3%2C 5%2C 1%2C 2%2C%0A        4%2C 4%2C 6%2C 3%2C 5%2C 5%2C 6%2C 0%2C 4%2C 1%2C 9%2C 5%2C 7%2C 8%2C 9%2C 3%5D%29" isContainer="True" shape="(64,)" />
<var name="examples" type="_SingleProcessDataLoaderIter" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x1518d98b0&gt;" isContainer="True" shape="157" />
<var name="fig" type="Figure" qualifier="matplotlib.figure" value="%3CFigure size 640x480 with 6 Axes&gt;" isContainer="True" />
<var name="hidden_size" type="int" qualifier="builtins" value="128" />
<var name="i" type="int" qualifier="builtins" value="5" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="model" type="MLP" qualifier="__main__" value="MLP%28%0A  %28fc1%29%3A Linear%28in_features=784%2C out_features=128%2C bias=True%29%0A  %28relu1%29%3A ReLU%28%29%0A  %28fc2%29%3A Linear%28in_features=128%2C out_features=128%2C bias=True%29%0A  %28relu2%29%3A ReLU%28%29%0A  %28fc3%29%3A Linear%28in_features=128%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" />
<var name="optimizer" type="Adam" qualifier="torch.optim.adam" value="Adam %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    initial_lr%3A 0.001%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="outputs" type="Tensor" qualifier="torch" value="tensor%28%5B%5B-4.4979e%2B01%2C -3.6314e%2B01%2C -2.4818e%2B01%2C -1.2241e-01%2C -5.0165e%2B01%2C%0A         -3.6805e%2B01%2C -8.5459e%2B01%2C  4.2051e%2B01%2C -4.1...-4.7492e%2B01%2C -1.0279e%2B01%2C  3.9232e%2B01%2C -9.2660e%2B01%2C%0A         -4.2278e%2B01%2C -1.0490e%2B02%2C -3.3722e%2B01%2C -2.4868e%2B01%2C -2.3130e%2B01%5D%5D%29" isContainer="True" shape="(64, 10)" />
<var name="pred" type="Tensor" qualifier="torch" value="tensor%28%5B7%2C 2%2C 1%2C 0%2C 4%2C 1%2C 4%2C 9%2C 5%2C 9%2C 0%2C 6%2C 9%2C 0%2C 1%2C 5%2C 9%2C 7%2C 3%2C 4%2C 9%2C 6%2C 6%2C 5%2C%0A        4%2C 0%2C 7%2C 4%2C 0%2C 1%2C 3%2C 1%2C 3%2C 4%2C 7%2C 2%2C 7%2C 1%2C 2%2C 1%2C 1%2C 7%2C 4%2C 2%2C 3%2C 5%2C 1%2C 2%2C%0A        4%2C 4%2C 6%2C 3%2C 5%2C 5%2C 6%2C 0%2C 4%2C 1%2C 9%2C 5%2C 7%2C 8%2C 9%2C 3%5D%29" isContainer="True" shape="(64,)" />
<var name="scheduler" type="StepLR" qualifier="torch.optim.lr_scheduler" value="%3Ctorch.optim.lr_scheduler.StepLR object at 0x151a8d1f0&gt;" isContainer="True" />
<var name="test_acc" type="float" qualifier="builtins" value="0.9837" />
<var name="test_dataset" type="MNIST" qualifier="torchvision.datasets.mnist" value="Dataset MNIST%0A    Number of datapoints%3A 10000%0A    Root location%3A ./data%0A    Split%3A Test%0A    StandardTransform%0ATransform%3A Compose%28%0A               ToTensor%28%29%0A               Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A           %29" isContainer="True" shape="10000" />
<var name="test_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x1518e4910&gt;" isContainer="True" shape="157" />
<var name="test_loss" type="float" qualifier="builtins" value="0.17489853962994478" />
<var name="train_dataset" type="MNIST" qualifier="torchvision.datasets.mnist" value="Dataset MNIST%0A    Number of datapoints%3A 60000%0A    Root location%3A ./data%0A    Split%3A Train%0A    StandardTransform%0ATransform%3A Compose%28%0A               ToTensor%28%29%0A               Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A           %29" isContainer="True" shape="60000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x144524040&gt;" isContainer="True" shape="938" />
<var name="training_acc" type="float" qualifier="builtins" value="1.0" />
<var name="training_loss" type="float" qualifier="builtins" value="2.1618982535816112e-08" />
<var name="transform" type="Compose" qualifier="torchvision.transforms.transforms" value="Compose%28%0A    ToTensor%28%29%0A    Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A%29" isContainer="True" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="MNIST_model" type="MLP" qualifier="__main__" value="MLP%28%0A  %28fc1%29%3A Linear%28in_features=784%2C out_features=128%2C bias=True%29%0A  %28relu1%29%3A ReLU%28%29%0A  %28fc2%29%3A Linear%28in_features=128%2C out_features=128%2C bias=True%29%0A  %28relu2%29%3A ReLU%28%29%0A  %28fc3%29%3A Linear%28in_features=128%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" />
<var name="batch_size" type="int" qualifier="builtins" value="64" />
<var name="criterion" type="CrossEntropyLoss" qualifier="torch.nn.modules.loss" value="CrossEntropyLoss%28%29" isContainer="True" />
<var name="epoch" type="int" qualifier="builtins" value="299" />
<var name="epochs" type="int" qualifier="builtins" value="300" />
<var name="example_data" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B%5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ......%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%2C%0A          %5B-1.%2C -1.%2C -1.%2C  ...%2C -1.%2C -1.%2C -1.%5D%5D%5D%5D%29" isContainer="True" shape="(64, 1, 28, 28)" />
<var name="example_labels" type="Tensor" qualifier="torch" value="tensor%28%5B7%2C 2%2C 1%2C 0%2C 4%2C 1%2C 4%2C 9%2C 5%2C 9%2C 0%2C 6%2C 9%2C 0%2C 1%2C 5%2C 9%2C 7%2C 3%2C 4%2C 9%2C 6%2C 6%2C 5%2C%0A        4%2C 0%2C 7%2C 4%2C 0%2C 1%2C 3%2C 1%2C 3%2C 4%2C 7%2C 2%2C 7%2C 1%2C 2%2C 1%2C 1%2C 7%2C 4%2C 2%2C 3%2C 5%2C 1%2C 2%2C%0A        4%2C 4%2C 6%2C 3%2C 5%2C 5%2C 6%2C 0%2C 4%2C 1%2C 9%2C 5%2C 7%2C 8%2C 9%2C 3%5D%29" isContainer="True" shape="(64,)" />
<var name="examples" type="_SingleProcessDataLoaderIter" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x1518d98b0&gt;" isContainer="True" shape="157" />
<var name="fig" type="Figure" qualifier="matplotlib.figure" value="%3CFigure size 640x480 with 6 Axes&gt;" isContainer="True" />
<var name="hidden_size" type="int" qualifier="builtins" value="128" />
<var name="i" type="int" qualifier="builtins" value="5" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="model" type="MLP" qualifier="__main__" value="MLP%28%0A  %28fc1%29%3A Linear%28in_features=784%2C out_features=128%2C bias=True%29%0A  %28relu1%29%3A ReLU%28%29%0A  %28fc2%29%3A Linear%28in_features=128%2C out_features=128%2C bias=True%29%0A  %28relu2%29%3A ReLU%28%29%0A  %28fc3%29%3A Linear%28in_features=128%2C out_features=10%2C bias=True%29%0A%29" isContainer="True" />
<var name="optimizer" type="Adam" qualifier="torch.optim.adam" value="Adam %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    initial_lr%3A 0.001%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="outputs" type="Tensor" qualifier="torch" value="tensor%28%5B%5B-4.4979e%2B01%2C -3.6314e%2B01%2C -2.4818e%2B01%2C -1.2241e-01%2C -5.0165e%2B01%2C%0A         -3.6805e%2B01%2C -8.5459e%2B01%2C  4.2051e%2B01%2C -4.1...-4.7492e%2B01%2C -1.0279e%2B01%2C  3.9232e%2B01%2C -9.2660e%2B01%2C%0A         -4.2278e%2B01%2C -1.0490e%2B02%2C -3.3722e%2B01%2C -2.4868e%2B01%2C -2.3130e%2B01%5D%5D%29" isContainer="True" shape="(64, 10)" />
<var name="pred" type="Tensor" qualifier="torch" value="tensor%28%5B7%2C 2%2C 1%2C 0%2C 4%2C 1%2C 4%2C 9%2C 5%2C 9%2C 0%2C 6%2C 9%2C 0%2C 1%2C 5%2C 9%2C 7%2C 3%2C 4%2C 9%2C 6%2C 6%2C 5%2C%0A        4%2C 0%2C 7%2C 4%2C 0%2C 1%2C 3%2C 1%2C 3%2C 4%2C 7%2C 2%2C 7%2C 1%2C 2%2C 1%2C 1%2C 7%2C 4%2C 2%2C 3%2C 5%2C 1%2C 2%2C%0A        4%2C 4%2C 6%2C 3%2C 5%2C 5%2C 6%2C 0%2C 4%2C 1%2C 9%2C 5%2C 7%2C 8%2C 9%2C 3%5D%29" isContainer="True" shape="(64,)" />
<var name="scheduler" type="StepLR" qualifier="torch.optim.lr_scheduler" value="%3Ctorch.optim.lr_scheduler.StepLR object at 0x151a8d1f0&gt;" isContainer="True" />
<var name="test_acc" type="float" qualifier="builtins" value="0.9837" />
<var name="test_dataset" type="MNIST" qualifier="torchvision.datasets.mnist" value="Dataset MNIST%0A    Number of datapoints%3A 10000%0A    Root location%3A ./data%0A    Split%3A Test%0A    StandardTransform%0ATransform%3A Compose%28%0A               ToTensor%28%29%0A               Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A           %29" isContainer="True" shape="10000" />
<var name="test_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x1518e4910&gt;" isContainer="True" shape="157" />
<var name="test_loss" type="float" qualifier="builtins" value="0.17489853962994478" />
<var name="train_dataset" type="MNIST" qualifier="torchvision.datasets.mnist" value="Dataset MNIST%0A    Number of datapoints%3A 60000%0A    Root location%3A ./data%0A    Split%3A Train%0A    StandardTransform%0ATransform%3A Compose%28%0A               ToTensor%28%29%0A               Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A           %29" isContainer="True" shape="60000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x144524040&gt;" isContainer="True" shape="938" />
<var name="training_acc" type="float" qualifier="builtins" value="1.0" />
<var name="training_loss" type="float" qualifier="builtins" value="2.1618982535816112e-08" />
<var name="transform" type="Compose" qualifier="torchvision.transforms.transforms" value="Compose%28%0A    ToTensor%28%29%0A    Normalize%28mean=%280.5%2C%29%2C std=%280.5%2C%29%29%0A%29" isContainer="True" />
</xml>
epoch 1 of 300: training_loss = 0.3673, training_accuracy = 0.8922, test_loss = 0.1877, test_accuracy = 0.9386
epoch 2 of 300: training_loss = 0.1709, training_accuracy = 0.9486, test_loss = 0.1417, test_accuracy = 0.9558
epoch 3 of 300: training_loss = 0.1234, training_accuracy = 0.9628, test_loss = 0.1073, test_accuracy = 0.9660
epoch 4 of 300: training_loss = 0.1021, training_accuracy = 0.9684, test_loss = 0.1056, test_accuracy = 0.9650
epoch 5 of 300: training_loss = 0.0858, training_accuracy = 0.9727, test_loss = 0.1110, test_accuracy = 0.9656
epoch 6 of 300: training_loss = 0.0730, training_accuracy = 0.9765, test_loss = 0.1096, test_accuracy = 0.9650
epoch 7 of 300: training_loss = 0.0670, training_accuracy = 0.9780, test_loss = 0.0858, test_accuracy = 0.9731
epoch 8 of 300: training_loss = 0.0607, training_accuracy = 0.9804, test_loss = 0.0862, test_accuracy = 0.9740
epoch 9 of 300: training_loss = 0.0529, training_accuracy = 0.9829, test_loss = 0.0807, test_accuracy = 0.9774
epoch 10 of 300: training_loss = 0.0508, training_accuracy = 0.9829, test_loss = 0.0907, test_accuracy = 0.9736
epoch 11 of 300: training_loss = 0.0445, training_accuracy = 0.9852, test_loss = 0.0899, test_accuracy = 0.9734
epoch 12 of 300: training_loss = 0.0427, training_accuracy = 0.9856, test_loss = 0.0800, test_accuracy = 0.9777
epoch 13 of 300: training_loss = 0.0391, training_accuracy = 0.9866, test_loss = 0.0774, test_accuracy = 0.9786
epoch 14 of 300: training_loss = 0.0352, training_accuracy = 0.9878, test_loss = 0.0874, test_accuracy = 0.9751
epoch 15 of 300: training_loss = 0.0347, training_accuracy = 0.9881, test_loss = 0.0914, test_accuracy = 0.9763
epoch 16 of 300: training_loss = 0.0336, training_accuracy = 0.9881, test_loss = 0.0892, test_accuracy = 0.9777
epoch 17 of 300: training_loss = 0.0294, training_accuracy = 0.9897, test_loss = 0.0914, test_accuracy = 0.9785
epoch 18 of 300: training_loss = 0.0273, training_accuracy = 0.9904, test_loss = 0.1052, test_accuracy = 0.9750
epoch 19 of 300: training_loss = 0.0279, training_accuracy = 0.9906, test_loss = 0.1033, test_accuracy = 0.9741
epoch 20 of 300: training_loss = 0.0280, training_accuracy = 0.9903, test_loss = 0.0882, test_accuracy = 0.9784
epoch 21 of 300: training_loss = 0.0164, training_accuracy = 0.9943, test_loss = 0.0891, test_accuracy = 0.9785
epoch 22 of 300: training_loss = 0.0150, training_accuracy = 0.9950, test_loss = 0.1081, test_accuracy = 0.9763
epoch 23 of 300: training_loss = 0.0171, training_accuracy = 0.9938, test_loss = 0.0983, test_accuracy = 0.9790
epoch 24 of 300: training_loss = 0.0164, training_accuracy = 0.9943, test_loss = 0.0915, test_accuracy = 0.9809
epoch 25 of 300: training_loss = 0.0144, training_accuracy = 0.9950, test_loss = 0.0978, test_accuracy = 0.9794
epoch 26 of 300: training_loss = 0.0167, training_accuracy = 0.9941, test_loss = 0.1061, test_accuracy = 0.9791
epoch 27 of 300: training_loss = 0.0132, training_accuracy = 0.9956, test_loss = 0.1254, test_accuracy = 0.9750
epoch 28 of 300: training_loss = 0.0121, training_accuracy = 0.9959, test_loss = 0.1006, test_accuracy = 0.9792
epoch 29 of 300: training_loss = 0.0161, training_accuracy = 0.9947, test_loss = 0.1139, test_accuracy = 0.9792
epoch 30 of 300: training_loss = 0.0133, training_accuracy = 0.9955, test_loss = 0.1160, test_accuracy = 0.9782
epoch 31 of 300: training_loss = 0.0127, training_accuracy = 0.9953, test_loss = 0.1130, test_accuracy = 0.9778
epoch 32 of 300: training_loss = 0.0075, training_accuracy = 0.9976, test_loss = 0.1216, test_accuracy = 0.9775
epoch 33 of 300: training_loss = 0.0178, training_accuracy = 0.9941, test_loss = 0.1254, test_accuracy = 0.9769
epoch 34 of 300: training_loss = 0.0087, training_accuracy = 0.9972, test_loss = 0.1224, test_accuracy = 0.9791
epoch 35 of 300: training_loss = 0.0118, training_accuracy = 0.9959, test_loss = 0.1466, test_accuracy = 0.9734
